{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.utils import np_utils,print_summary,to_categorical\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "              \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(r'C:\\Users\\Admin\\jupyter projects\\devnagri.csv',header=0)\n",
    "dataset= np.array(data)\n",
    "x=dataset\n",
    "y=dataset\n",
    "x=x[:,0:1024]\n",
    "y=y[:,1024]\n",
    "\n",
    "#splitting the data into training and testing set, normalizing the values\n",
    "x_train=x[0:71000,:]    # 71000 samples in training set\n",
    "x_train=x_train/255     # coverting the pixel values0-255 into 0-1\n",
    "x_test=x[71000:72001,:] # 1000 samples in testing set\n",
    "x_test=x_test/255\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of training examples:71000\n",
      "no. of test examples:1000\n",
      "x_train shape:(71000, 1024)\n",
      "x_test shape:(1000, 1024)\n",
      "y_train shape:(1, 71000)\n",
      "y_test shape: (1, 1000)\n",
      "x_train shape:(71000, 32, 32, 1)\n",
      "y_train shape:(71000, 37)\n"
     ]
    }
   ],
   "source": [
    "# reshaping the y values to ensure correct dimensionality\n",
    "y=y.reshape(y.shape[0],1)\n",
    "y_train=y[0:71000,:]\n",
    "y_train=y_train.T\n",
    "y_test=y[71000:72001,:]\n",
    "y_test=y_test.T\n",
    "\n",
    "# to check dimensionality of test and train data\n",
    "print(\"no. of training examples:\"+str(x_train.shape[0]))\n",
    "print(\"no. of test examples:\"+str(x_test.shape[0]))\n",
    "print(\"x_train shape:\"+ str(x_train.shape))\n",
    "print(\"x_test shape:\"+ str(x_test.shape))\n",
    "print(\"y_train shape:\"+str(y_train.shape))\n",
    "print(\"y_test shape: \"+str(y_test.shape))\n",
    "\n",
    "image_x,image_y=32,32   # defining the dimension of image\n",
    "train_y=np_utils.to_categorical(y_train)  # converting integers values to binary values\n",
    "test_y=np_utils.to_categorical(y_test)\n",
    "train_y=train_y.reshape(train_y.shape[1],train_y.shape[2])\n",
    "test_y=test_y.reshape(test_y.shape[1],test_y.shape[2])\n",
    "x_train=x_train.reshape(x_train.shape[0],image_x,image_y,1) # 1 is for gray image\n",
    "x_test=x_test.reshape(x_test.shape[0],image_x,image_y,1)\n",
    "print(\"x_train shape:\"+ str(x_train.shape))\n",
    "print(\"y_train shape:\"+ str(train_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0927 20:41:53.067623   368 deprecation_wrapper.py:119] From C:\\Users\\Admin\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0927 20:41:53.855192   368 deprecation_wrapper.py:119] From C:\\Users\\Admin\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0927 20:41:54.058294   368 deprecation_wrapper.py:119] From C:\\Users\\Admin\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0927 20:41:54.397641   368 deprecation_wrapper.py:119] From C:\\Users\\Admin\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0927 20:41:54.720563   368 deprecation_wrapper.py:119] From C:\\Users\\Admin\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0927 20:41:54.770491   368 deprecation_wrapper.py:119] From C:\\Users\\Admin\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0927 20:41:55.599908   368 deprecation.py:323] From C:\\Users\\Admin\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0927 20:41:55.845320   368 deprecation_wrapper.py:119] From C:\\Users\\Admin\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 71000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "71000/71000 [==============================] - 65s 922us/step - loss: 1.0920 - acc: 0.6939 - val_loss: 1.1442 - val_acc: 0.6230\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.62300, saving model to devnagri.h5\n",
      "Epoch 2/3\n",
      "71000/71000 [==============================] - 25s 351us/step - loss: 0.4051 - acc: 0.8802 - val_loss: 2.9462 - val_acc: 0.2630\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.62300\n",
      "Epoch 3/3\n",
      "71000/71000 [==============================] - 26s 359us/step - loss: 0.2869 - acc: 0.9135 - val_loss: 0.9086 - val_acc: 0.7110\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.62300 to 0.71100, saving model to devnagri.h5\n",
      "CNN ERROR: 28.90%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 2, 2, 64)          51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 37)                2405      \n",
      "=================================================================\n",
      "Total params: 54,501\n",
      "Trainable params: 54,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building a model\n",
    "def keras_model(image_x,image_y): # height and width of image\n",
    "    n_classes=37    # from y_train shape\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu',input_shape=(image_x,image_y,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),strides=(5,5),padding='same'))\n",
    "    model.add(Conv2D(64,(5,5),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(5,5),strides=(5,5),padding='same'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_classes,activation=\"softmax\"))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    filepath=\"devnagri.h5\"\n",
    "    checkpoint1=ModelCheckpoint(filepath,monitor='val_acc',verbose=1,save_best_only=True,mode='max')\n",
    "    callbacks_list=[checkpoint1]\n",
    "              \n",
    "    return model,callbacks_list            \n",
    "\n",
    "model,callbacks_list=keras_model(image_x,image_y)\n",
    "model.fit(x_train,train_y,validation_data=(x_test,test_y),epochs=3,batch_size=64,callbacks=callbacks_list)\n",
    "score=model.evaluate(x_test,test_y,verbose=0)\n",
    "print(\"CNN ERROR: %.2f%%\" % (100-score[1]*100))\n",
    "print_summary(model)\n",
    "model.save(\"devnagri.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1130 21:08:38.795664  5048 deprecation_wrapper.py:119] From C:\\Users\\Admin\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1130 21:08:39.049844  5048 deprecation_wrapper.py:119] From C:\\Users\\Admin\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1130 21:08:39.264998  5048 deprecation_wrapper.py:119] From C:\\Users\\Admin\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1130 21:08:39.974500  5048 deprecation_wrapper.py:119] From C:\\Users\\Admin\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1130 21:08:39.997515  5048 deprecation_wrapper.py:119] From C:\\Users\\Admin\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1130 21:08:40.007525  5048 deprecation_wrapper.py:119] From C:\\Users\\Admin\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W1130 21:08:47.793569  5048 deprecation_wrapper.py:119] From C:\\Users\\Admin\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1130 21:08:48.927372  5048 deprecation.py:323] From C:\\Users\\Admin\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x00000008DFC172C8>\n"
     ]
    }
   ],
   "source": [
    "#Application:\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "from collections import deque\n",
    "\n",
    "model1=load_model('devnagri.h5')\n",
    "print(model1)\n",
    "\n",
    "letter_count = {0: 'CHECK', 1: '01_ka', 2: '02_kha', 3: '03_ga', 4: '04_gha', 5: '05_kna', 6: 'character_06_cha',\n",
    "                7: '07_chha', 8: '08_ja', 9: '09_jha', 10: '10_yna',\n",
    "                11: '11_taamatar',\n",
    "                12: '12_thaa', 13: '13_daa', 14: '14_dhaa', 15: '15_adna', 16: '16_tabala', 17: '17_tha',\n",
    "                18: '18_da', 19: '19_dha', 20: '20_na', 21: '21_pa', 22: '22_pha',\n",
    "                23: '23_ba', 24: '24_bha', 25: '25_ma', 26: '26_yaw', 27: '27_ra', 28: '28_la', 29: '29_waw', 30: '30_motosaw',\n",
    "                31: '31_petchiryakha',32: '32_patalosaw', 33: '33_ha',\n",
    "                34: '34_chhya', 35: '35_tra', 36: '36_gya', 37: 'CHECK'}\n",
    "\n",
    "def keras_predict(model, image):\n",
    "    processed = keras_process_image(image)\n",
    "    print(\"processed: \" + str(processed.shape))\n",
    "    pred_probab = model.predict(processed)[0]\n",
    "    pred_class = list(pred_probab).index(max(pred_probab))\n",
    "    return max(pred_probab), pred_class\n",
    "\n",
    "\n",
    "def keras_process_image(img):\n",
    "    image_x = 32\n",
    "    image_y = 32\n",
    "    img = cv2.resize(img, (image_x, image_y))\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    img = np.reshape(img, (-1, image_x, image_y, 1))\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "try:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    vid_cod = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "    output = cv2.VideoWriter(\"cam_video.avi\", vid_cod, 20.0, (640,480))\n",
    "    Lower_blue = np.array([110, 50, 50])\n",
    "    Upper_blue = np.array([130, 255, 255])\n",
    "    pred_class=0\n",
    "    pts = deque(maxlen=512)\n",
    "    blackboard = np.zeros((480, 640, 3), dtype=np.uint8)       # will return zero matrix of shape 480*640\n",
    "    digit = np.zeros((200, 200, 3), dtype=np.uint8)  #will return zero matrix of shape 200*200\n",
    "    while (cap.isOpened()):                  #while camera is opened\n",
    "         ret, img = cap.read()     # reading the image\n",
    "         img = cv2.flip(img, 1)   #flipping the image\n",
    "         imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)    #coverting the image from RGB format to HSV \n",
    "         mask = cv2.inRange(imgHSV, Lower_blue, Upper_blue)  # defining the range where mask is applied on HSV image\n",
    "         blur = cv2.medianBlur(mask, 15) # blurring the unrequired points using median blur on mask image\n",
    "         blur = cv2.GaussianBlur(blur, (5, 5), 0) #blurring using gaussian blur\n",
    "         thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1] # defining the threshold values\n",
    "         cnts = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[1] # defining the contours for getting the required feature\n",
    "         # extracting blue colour from countour\n",
    "         center = None\n",
    "         if len(cnts) >= 1:   # finding if contour is available\n",
    "            contour = max(cnts, key=cv2.contourArea)\n",
    "            if cv2.contourArea(contour) > 250:  #if contour area is greater than 250 \n",
    "                ((x, y), radius) = cv2.minEnclosingCircle(contour) # enclosing it in circle\n",
    "                cv2.circle(img, (int(x), int(y)), int(radius), (0, 255, 255), 2)\n",
    "                cv2.circle(img, center, 5, (0, 0, 255), -1)\n",
    "                M = cv2.moments(contour) # to calculate moments of contour\n",
    "                center = (int(M['m10'] / M['m00']), int(M['m01'] / M['m00'])) # deciding the center point\n",
    "                pts.appendleft(center) # appending the center point in a list\n",
    "                for i in range(1, len(pts)):   \n",
    "                    if pts[i - 1] is None or pts[i] is None:\n",
    "                        continue\n",
    "                    cv2.line(blackboard, pts[i - 1], pts[i], (255, 255, 255), 10)\n",
    "                    cv2.line(img, pts[i - 1], pts[i], (0, 0, 255), 5)\n",
    "         elif len(cnts) == 0:\n",
    "            if len(pts) != []:\n",
    "                blackboard_gray = cv2.cvtColor(blackboard, cv2.COLOR_BGR2GRAY) # convert it into gray colour\n",
    "                blur1 = cv2.medianBlur(blackboard_gray, 15)\n",
    "                blur1 = cv2.GaussianBlur(blur1, (5, 5), 0)\n",
    "                thresh1 = cv2.threshold(blur1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "                blackboard_cnts = cv2.findContours(thresh1.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[1]\n",
    "                if len(blackboard_cnts) >= 1:\n",
    "                     cnt = max(blackboard_cnts, key=cv2.contourArea)\n",
    "                     print(cv2.contourArea(cnt))\n",
    "                     if cv2.contourArea(cnt) > 2000:\n",
    "                            x, y, w, h = cv2.boundingRect(cnt)\n",
    "                            digit = blackboard_gray[y:y + h, x:x + w]\n",
    "                            # newImage = process_letter(digit)\n",
    "                            pred_probab, pred_class = keras_predict(model1, digit)\n",
    "                            print(pred_class, pred_probab)\n",
    "\n",
    "                     pts = deque(maxlen=512)\n",
    "                     blackboard = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "         cv2.putText(img, \"Conv Network :  \" + str(letter_count[pred_class]), (10, 470),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "         output.write(img)\n",
    "         cv2.imshow(\"Frame\", img)\n",
    "         #cv2.imshow(\"Contours\", thresh)\n",
    "         if cv2.waitKey(25)&0XFF == ord('x'):\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "# close the already opened file\n",
    "    output.release()\n",
    "# close the window and de-allocate any associated memory usage\n",
    "    cv2.destroyAllWindows()\n",
    "        \n",
    "except cv2.error as e:\n",
    "     pass         \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
